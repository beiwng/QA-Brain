"""
LangGraph RAG Workflow
å®ç° Retrieve -> Grade -> Generate çš„æ™ºèƒ½åˆ†ææµç¨‹
"""
from typing import TypedDict, List, Dict, Any
from langgraph.graph import StateGraph, END
from backend.utils.vector_service import vector_service
from backend.utils.llm_service import llm_service


# === State Definition ===
class AgentState(TypedDict):
    """Agent çŠ¶æ€å®šä¹‰"""
    query: str  # ç”¨æˆ·è¾“å…¥
    retrieved_decisions: List[Dict[str, Any]]  # æ£€ç´¢åˆ°çš„å†³ç­– (Policy)
    retrieved_bugs: List[Dict[str, Any]]  # æ£€ç´¢åˆ°çš„å†å²ç¼ºé™· (Technical) - âœ… æ–°å¢
    relevance_score: float  # ç›¸å…³æ€§è¯„åˆ†
    final_answer: str  # æœ€ç»ˆç­”æ¡ˆ
    severity: str  # ä¸¥é‡ç¨‹åº¦
    sources: List[str]  # å¼•ç”¨æ¥æº


# === Node Functions ===
async def retrieve_node(state: AgentState) -> AgentState:
    """
    èŠ‚ç‚¹ 1: æ£€ç´¢ (Retrieve)
    ä»å‘é‡åº“ä¸­é€šç”¨æ£€ç´¢ï¼Œå¹¶åˆ†ç±»ä¸ºå†³ç­–å’Œç¼ºé™·
    """
    query = state["query"]
    print(f"ğŸ” [Retrieve] Searching for: {query}")

    try:
        # âœ… é€‚é…ï¼šè°ƒç”¨æ–°çš„é€šç”¨æ£€ç´¢æ¥å£
        # top_k ç¨å¾®å¤§ä¸€ç‚¹ï¼Œå› ä¸ºåŒ…å«äº†ä¸¤ç§ç±»å‹çš„æ•°æ®
        documents = await vector_service.search_similar(query, top_k=10)

        decisions = []
        bugs = []

        # âœ… é€‚é…ï¼šæ ¹æ® source_type æ‹†åˆ†æ•°æ®
        for doc in documents:
            source = doc.get("source_type", "")
            if source == "decision":
                decisions.append(doc)
            elif source == "bug_history":
                bugs.append(doc)

        print(f"âœ… [Retrieve] Found {len(decisions)} decisions, {len(bugs)} bugs")

        # è¿”å›çŠ¶æ€æ›´æ–°
        return {
            "retrieved_decisions": decisions,
            "retrieved_bugs": bugs
        }

    except Exception as e:
        print(f"âŒ [Retrieve] Error: {e}")
        import traceback
        traceback.print_exc()
        return {
            "retrieved_decisions": [],
            "retrieved_bugs": []
        }


async def grade_node(state: AgentState) -> AgentState:
    """
    èŠ‚ç‚¹ 2: è¯„ä¼°ç›¸å…³æ€§
    åˆ¤æ–­æ£€ç´¢ç»“æœæ˜¯å¦è¶³å¤Ÿç›¸å…³ï¼ˆæœ€å¤§å€¼ç­–ç•¥ï¼‰
    """
    decisions = state.get("retrieved_decisions", [])
    bugs = state.get("retrieved_bugs", [])

    # åˆå¹¶æ‰€æœ‰æ–‡æ¡£è®¡ç®—æœ€é«˜åˆ†
    all_docs = decisions + bugs

    if not all_docs:
        state["relevance_score"] = 0.0
        print("âš ï¸ [Grade] No documents found, relevance = 0.0")
        return state

    # âœ… é€‚é…ï¼šå–æœ€å¤§åˆ†ï¼Œåªè¦æœ‰ä¸€æ¡å‘½ä¸­å³å¯
    max_score = max(d.get("score", 0.0) for d in all_docs)
    state["relevance_score"] = max_score

    print(f"ğŸ“Š [Grade] Max relevance score: {max_score:.2f}")

    return state


async def generate_node(state: AgentState) -> AgentState:
    """
    èŠ‚ç‚¹ 3: ç”Ÿæˆç­”æ¡ˆ
    è°ƒç”¨ LLM ç”Ÿæˆä¸“ä¸šçš„ Bug åˆ†ææŠ¥å‘Š
    """
    query = state["query"]
    decisions = state.get("retrieved_decisions", [])
    bugs = state.get("retrieved_bugs", [])
    relevance = state["relevance_score"]

    # ç›¸å…³æ€§é˜ˆå€¼åˆ¤æ–­ (IP/Cosine é€šå¸¸ 0.35-0.4 ç®—ç›¸å…³)
    RELEVANCE_THRESHOLD = 0.4

    if relevance < RELEVANCE_THRESHOLD:
        print(f"âš ï¸ [Generate] Relevance too low ({relevance:.2f} < {RELEVANCE_THRESHOLD}), returning fallback")
        state["final_answer"] = """## âš ï¸ çŸ¥è¯†åº“èµ„æ–™ä¸è¶³

å¾ˆæŠ±æ­‰ï¼ŒQA-Brain åœ¨å†å²å†³ç­–åº“æˆ–ç¼ºé™·åº“ä¸­æœªæ‰¾åˆ°ä¸æ­¤é—®é¢˜é«˜åº¦ç›¸å…³çš„è®°å½•ã€‚

**å»ºè®®**ï¼š
1. è¯·æä¾›æ›´è¯¦ç»†çš„é”™è¯¯æ—¥å¿—æˆ–å¤ç°æ­¥éª¤
2. å’¨è¯¢å›¢é˜Ÿä¸­çš„èµ„æ·±å·¥ç¨‹å¸ˆ
3. è‹¥ç¡®è®¤ä¸ºæ–°é—®é¢˜ï¼Œè¯·åŠæ—¶å½•å…¥çŸ¥è¯†åº“
"""
        state["severity"] = "Major"
        state["sources"] = []
        return state

    # è°ƒç”¨ LLM ç”Ÿæˆåˆ†æ
    print(f"ğŸ¤– [Generate] Calling LLM for analysis...")
    try:
        # âœ… é€‚é…ï¼šä¼ å…¥åŒæµä¸Šä¸‹æ–‡ (å†³ç­– + Bug)
        result = await llm_service.analyze_bug(
            query=query,
            context_decisions=decisions,
            context_bugs=bugs
        )

        state["final_answer"] = result["answer"]
        state["severity"] = result["severity"]
        state["sources"] = result["sources"]

        print(f"âœ… [Generate] Analysis complete (Severity: {result['severity']})")

    except Exception as e:
        print(f"âŒ [Generate] LLM error: {e}")
        import traceback
        traceback.print_exc()

        state["final_answer"] = f"## âŒ åˆ†æå¤±è´¥\n\nç³»ç»Ÿé”™è¯¯: {str(e)}"
        state["severity"] = "Major"
        state["sources"] = []

    return state


# === Build Graph ===
def build_graph() -> StateGraph:
    """æ„å»º LangGraph å·¥ä½œæµ"""
    workflow = StateGraph(AgentState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("retrieve", retrieve_node)
    workflow.add_node("grade", grade_node)
    workflow.add_node("generate", generate_node)

    # å®šä¹‰è¾¹
    workflow.set_entry_point("retrieve")
    workflow.add_edge("retrieve", "grade")
    workflow.add_edge("grade", "generate")
    workflow.add_edge("generate", END)

    return workflow.compile()


# === Main Entry ===
async def analyze_bug_with_graph(query: str) -> Dict[str, Any]:
    """
    ä¸»å…¥å£ï¼šä½¿ç”¨ LangGraph åˆ†æ Bug
    """
    print(f"\n{'=' * 60}")
    print(f"ğŸ§  QA-Brain Analysis Started: {query}")
    print(f"{'=' * 60}\n")

    # åˆå§‹åŒ–çŠ¶æ€
    initial_state: AgentState = {
        "query": query,
        "retrieved_decisions": [],
        "retrieved_bugs": [],  # âœ… åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
        "relevance_score": 0.0,
        "final_answer": "",
        "severity": "Major",
        "sources": []
    }

    try:
        # è¿è¡Œ Graph
        app = build_graph()
        final_state = await app.ainvoke(initial_state)

        print(f"\n{'=' * 60}")
        print(f"âœ… QA-Brain Analysis Completed")
        print(f"{'=' * 60}\n")

        return {
            "answer": final_state["final_answer"],
            "severity": final_state["severity"],
            "sources": final_state["sources"]
        }
    except Exception as e:
        print(f"âŒ Graph execution failed: {e}")
        import traceback
        traceback.print_exc()
        # å…œåº•è¿”å›
        return {
            "answer": f"ç³»ç»Ÿè¿è¡Œé”™è¯¯: {str(e)}",
            "severity": "Major",
            "sources": []
        }