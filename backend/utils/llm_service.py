"""
LLM æœåŠ¡å°è£…
ä½¿ç”¨ LangChain è°ƒç”¨ç§æœ‰åŒ–å¤§æ¨¡å‹
"""
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage
from backend.config import settings
from typing import Dict, Any, List, Optional


class LLMService:
    """å¤§æ¨¡å‹æœåŠ¡å°è£…"""

    def __init__(self):
        self.llm = ChatOpenAI(
            model=settings.LLM_MODEL,
            openai_api_key=settings.LLM_API_KEY,
            openai_api_base=settings.LLM_BASE_URL,
            temperature=0.3,
            max_tokens=4096
        )

    async def analyze_bug(
            self,
            query: str,
            context_decisions: List[Dict] = None,
            context_bugs: List[Dict] = None
    ) -> Dict[str, Any]:
        """
        åˆ†æ Bug å¹¶ç”ŸæˆæŠ¥å‘Š (èåˆå†³ç­–ä¸å†å²ç¼ºé™·)
        """
        if context_decisions is None: context_decisions = []
        if context_bugs is None: context_bugs = []

        # 1. æ„å»ºâ€œå†³ç­–â€ä¸Šä¸‹æ–‡ (ä¿æŒä¸å˜)
        decision_text = ""
        if context_decisions:
            decision_text = "\n\n### ğŸ“š ç›¸å…³é¡¹ç›®å†³ç­– (Policy Context)ï¼š\n"
            for d in context_decisions:
                decision_text += f"- [å†³ç­–#{d.get('id')}] {d.get('title')}\n"
                decision_text += f"  ç»“è®º: {d.get('verdict')}\n"
        else:
            decision_text = "\n\n### ğŸ“š ç›¸å…³é¡¹ç›®å†³ç­–ï¼š\n(æ— ç›¸å…³è®°å½•)"

        # 2. æ„å»ºâ€œå†å²ç¼ºé™·â€ä¸Šä¸‹æ–‡ (âœ… å·²æ–°å¢ impact_scope)
        bug_text = ""
        if context_bugs:
            bug_text = "\n\n### ğŸ ç›¸ä¼¼å†å²ç¼ºé™· (Technical Context)ï¼š\n"
            for b in context_bugs:
                # æ³¨æ„ï¼šb æ˜¯ä» Milvus metadata è§£æå‡ºæ¥çš„å­—å…¸
                bug_text += f"- [Bug#{b.get('id')}] {b.get('text')[:100]}...\n"
                bug_text += f"  æ ¹å› : {b.get('root_cause', 'æ— ')}\n"
                bug_text += f"  è§£å†³: {b.get('solution', 'æ— ')}\n"
                # --- æ–°å¢ ---
                bug_text += f"  èŒƒå›´: {b.get('impact_scope', 'æœªçŸ¥')}\n"
        else:
            bug_text = "\n\n### ğŸ ç›¸ä¼¼å†å²ç¼ºé™·ï¼š\n(æ— ç›¸å…³è®°å½•)"

        # 3. å‡çº§ System Prompt (âœ… å¼•å¯¼ AI å…³æ³¨å½±å“èŒƒå›´)
        system_prompt = """ä½ æ˜¯ QA-Brainï¼Œä¸€ä½èµ„æ·±çš„è½¯ä»¶æµ‹è¯•ä¸“å®¶ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæ£€ç´¢åˆ°çš„ã€é¡¹ç›®å†³ç­–ã€‘å’Œã€å†å²ç¼ºé™·ã€‘çŸ¥è¯†åº“ï¼Œå¯¹ç”¨æˆ·æäº¤çš„æ–° Bug è¿›è¡Œæ·±åº¦åˆ†æã€‚

**ä¸¥é‡ç¨‹åº¦åˆ¤å®šåŸåˆ™**ï¼š
- å¿…é¡»å‚è€ƒå†å²ç¼ºé™·çš„ã€å½±å“èŒƒå›´ (impact_scope)ã€‘ã€‚
- è‹¥å†å²é—®é¢˜æ¶‰åŠæ ¸å¿ƒä¸šåŠ¡æˆ–ç”Ÿäº§ç¯å¢ƒï¼Œæœ¬æ¬¡åˆ†æåº”å€¾å‘äºå®šçº§ä¸º High/Criticalã€‚

**åˆ†æé€»è¾‘é“¾**ï¼š
1. **ç­–ç•¥æ£€æŸ¥**ï¼šæŸ¥çœ‹å†³ç­–åº“ï¼Œç¡®è®¤æ˜¯å¦ä¸ºå·²çŸ¥è®¾è®¡æˆ–è±å…é¡¹ã€‚
2. **æŠ€æœ¯æ¯”å¯¹**ï¼šå¯¹æ¯”å†å² Bug çš„ã€æ ¹å› ã€‘ä¸ã€è§£å†³ã€‘ï¼Œæ¨æ–­å½“å‰é—®é¢˜ã€‚
3. **ç»¼åˆå®šçº§**ï¼šç»“åˆã€å½±å“èŒƒå›´ã€‘ç»™å‡ºä¸¥é‡ç¨‹åº¦ã€‚

**è¾“å‡ºè¦æ±‚**ï¼š
- è¾“å‡ºæ ¼å¼å¿…é¡»ä¸º Markdownã€‚
- å¼•ç”¨çŸ¥è¯†åº“å†…å®¹å¿…é¡»æ˜ç¡®æŒ‡å‡º IDã€‚
"""

        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹å¾…å¤„ç†é—®é¢˜ï¼š

## ğŸ› å¾…åˆ†æé—®é¢˜æè¿°
{query}

---
{decision_text}
---
{bug_text}
---

è¯·è¾“å‡º **Bug åˆ†ææŠ¥å‘Š** (Markdown)ã€‚
"""

        user_prompt = f"""è¯·åˆ†æä»¥ä¸‹å¾…å¤„ç†é—®é¢˜ï¼š

        ## ğŸ› å¾…åˆ†æé—®é¢˜æè¿°
        {query}

        ---
        {decision_text}
        ---
        {bug_text}
        ---

        è¯·è¾“å‡º **Bug åˆ†ææŠ¥å‘Š**ï¼ŒåŒ…å«ä»¥ä¸‹ç« èŠ‚ï¼š
        1. **é—®é¢˜å®šæ€§**ï¼š(æ˜¯ Bugã€éœ€æ±‚é—®é¢˜ã€è¿˜æ˜¯é‡å¤é—®é¢˜ï¼Ÿ)
        2. **ä¸¥é‡ç¨‹åº¦**ï¼š(Blocker/Critical/Major/Minor)
        3. **æ™ºèƒ½æ ¹å› æ¨æµ‹**ï¼š(ç»“åˆå†å²ç¼ºé™·çš„æ ¹å› è¿›è¡Œæ¨æ–­)
        4. **ä¿®å¤å»ºè®®**ï¼š(å‚è€ƒå†å²è§£å†³æ–¹æ¡ˆ)
        5. **çŸ¥è¯†åº“å¼•ç”¨**ï¼š(åˆ—å‡ºå‚è€ƒçš„å†³ç­– ID æˆ– å†å² Bug ID)
        """

        # è°ƒç”¨ LLM
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ]

        response = await self.llm.ainvoke(messages)
        answer = response.content

        # æå–ä¸¥é‡ç¨‹åº¦
        severity = self._extract_severity(answer)

        # æå–æ‰€æœ‰å¼•ç”¨çš„ Source ID (ç”¨äºå‰ç«¯å±•ç¤ºå¼•ç”¨æ¥æº)
        sources = []
        if context_decisions:
            sources.extend([f"å†³ç­–#{d.get('id')}" for d in context_decisions])
        if context_bugs:
            sources.extend([f"Bug#{b.get('id')}" for b in context_bugs])

        return {
            "answer": answer,
            "severity": severity,
            "sources": sources
        }

    def _extract_severity(self, text: str) -> str:
        """ä» LLM è¾“å‡ºä¸­æå–ä¸¥é‡ç¨‹åº¦"""
        severity_keywords = ["Blocker", "Critical", "Major", "Minor", "Trivial"]
        for keyword in severity_keywords:
            if keyword in text:
                return keyword
        return "Major"  # é»˜è®¤å€¼

# å…¨å±€å®ä¾‹
llm_service = LLMService()

